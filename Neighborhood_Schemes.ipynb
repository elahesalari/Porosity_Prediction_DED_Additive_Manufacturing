{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neighborhood Schemes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTg1TOqxjvBE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from math import sqrt\n",
        "import cv2\n",
        "import imutils\n",
        "import random\n",
        "from nltk import flatten"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def before_layers(n, x_i, y_i, x_i_1, y_i_1):\n",
        "    layer_1 = []\n",
        "    for b1 in range(len(x_i_1)):\n",
        "        layer_1.append(f\"{x_i_1[b1]} {y_i_1[b1]}\")\n",
        "\n",
        "    index = []\n",
        "    for p in range(len(x_i)):\n",
        "        current_x = x_i[p]\n",
        "        current_y = y_i[p]\n",
        "        i_1 = [list(map(float, x.split())) for x in layer_1]\n",
        "\n",
        "        distance = []\n",
        "        for c in i_1:\n",
        "            distance.append(sqrt(np.subtract(c[0], current_x) ** 2 + np.subtract(c[1], current_y) ** 2))\n",
        "\n",
        "        argsort_dis = np.argsort(distance)\n",
        "        index.append(argsort_dis[n])\n",
        "\n",
        "\n",
        "    return index"
      ],
      "metadata": {
        "id": "vIlPTWsCmKYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neighborhood_same_layer(n,x_i, y_i):\n",
        "    xy = []\n",
        "    for idx in range(len(x_i)):\n",
        "        xy.append(f\"{x_i[idx]} {y_i[idx]}\")\n",
        "    index = []\n",
        "    for p in range(len(x_i)):\n",
        "        current_x = x_i[p]\n",
        "        current_y = y_i[p]\n",
        "        xy_cor = [list(map(float, cor.split())) for cor in xy]\n",
        "\n",
        "        distance = []\n",
        "        for c in xy_cor:\n",
        "            distance.append(sqrt(np.subtract(c[0] , current_x)**2 + np.subtract(c[1] , current_y)**2))\n",
        "\n",
        "        argsort_dis = np.argsort(distance)\n",
        "        index.append(argsort_dis[n])\n",
        "    # print(len(index))\n",
        "    return index"
      ],
      "metadata": {
        "id": "fUVIqXXenxnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_neighborhood(data, features, depth_layer, state, num_neighbor):\n",
        "    dictionary = {}\n",
        "\n",
        "    def creat_neighbor_features():\n",
        "      feature_neighborhood = []\n",
        "      if state == '3D':\n",
        "        for d in range(1, depth_layer+1):\n",
        "          for n in range(1,num_neighbor+1):\n",
        "            for name in features:\n",
        "              feature_neighborhood.append(name+f'-{d}|N{n}')\n",
        "      elif state == '2D':\n",
        "        for n in range(1,num_neighbor+1):\n",
        "            for name in features:\n",
        "              feature_neighborhood.append(name+f'|N{n}')\n",
        "\n",
        "      return feature_neighborhood\n",
        "\n",
        "    feature_in_layer = []\n",
        "    feature_in_bottom_layer = []\n",
        "    for name in features:\n",
        "      globals()[name] = np.array(data[name])\n",
        "      feature_in_layer.append(name+'_layer')\n",
        "      feature_in_bottom_layer.append(name+'_bottom')\n",
        "\n",
        "\n",
        "    # Create dictionary keys  \n",
        "    feature_neighborhood = creat_neighbor_features()\n",
        "    dic_keys = list(features[:-1]) + feature_neighborhood + [features[-1]]\n",
        "    print('dic keys:',dic_keys)\n",
        "    for f in dic_keys:\n",
        "      dictionary[f] = []\n",
        "\n",
        "    # Get data points in each layer\n",
        "    value_z = np.unique(pos_z)\n",
        "    len_layer = len(value_z)\n",
        "    \n",
        "    for i in range(depth_layer, len_layer):\n",
        "        # All feature extracted from i_th layer\n",
        "        # ...i...\n",
        "        for name in feature_in_layer: \n",
        "          globals()[name] = globals()[name[:-6]][pos_z == value_z[i]]\n",
        "          dictionary[name[:-6]].append(globals()[name].tolist())\n",
        "        # ...i...\n",
        "\n",
        "        if state == '3D':\n",
        "          # All feature extracted from i-n_th layer\n",
        "          # ...i-n...\n",
        "          for depth in range(1, depth_layer+1):\n",
        "            for neighbor in range(num_neighbor):\n",
        "              for name in feature_in_bottom_layer: \n",
        "                globals()[name] = globals()[name[:-7]][pos_z == value_z[i-depth]]\n",
        "              \n",
        "              bottom_index = before_layers(neighbor, pos_x_layer, pos_y_layer, pos_x_bottom, pos_y_bottom)\n",
        "\n",
        "              for name in feature_in_bottom_layer: \n",
        "                globals()[name] = globals()[name][bottom_index]\n",
        "                dictionary[name[:-7]+f'-{depth}|N{neighbor+1}'].append(globals()[name].tolist())\n",
        "\n",
        "        elif state == '2D':\n",
        "          # print(len(pos_x_layer))\n",
        "          # All feature extracted from neighbors of i_th layer\n",
        "          for neighbor in range(1, num_neighbor+1):\n",
        "            neighbor_index = neighborhood_same_layer(neighbor, pos_x_layer, pos_y_layer)\n",
        "\n",
        "            for name in feature_in_layer:\n",
        "              dictionary[name[:-6]+f'|N{neighbor}'].append(globals()[name][neighbor_index].tolist())\n",
        "          \n",
        "\n",
        "              \n",
        "    \n",
        "\n",
        "    return dic_keys, dictionary\n"
      ],
      "metadata": {
        "id": "E0grnp8ntP9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_each_sample(flag, features , depth_layer, state, num_neighbor):\n",
        "    if flag == 'Sample 4':\n",
        "        path_img = '/content/drive/MyDrive/DED Codes/New images/Sample 4'\n",
        "        data = pd.read_csv('/content/drive/MyDrive/DED Codes/Porosity prediction in DED/DataPoints On Object/DataPoints Sample 4.csv')\n",
        "        angle = 10\n",
        "\n",
        "    elif flag == 'Sample 5':\n",
        "        path_img = '/content/drive/MyDrive/DED Codes/New images/Sample 5'\n",
        "        data = pd.read_csv('/content/drive/MyDrive/DED Codes/Porosity prediction in DED/DataPoints On Object/DataPoints Sample 5.csv')\n",
        "        angle = 100\n",
        "\n",
        "    elif flag == 'Sample 6':\n",
        "        path_img = '/content/drive/MyDrive/DED Codes/New images/Sample 6'\n",
        "        data = pd.read_csv('/content/drive/MyDrive/DED Codes/Porosity prediction in DED/DataPoints On Object/DataPoints Sample 6.csv')\n",
        "        angle = -85\n",
        "\n",
        "    elif flag == 'Sample 8':\n",
        "        path_img = '/content/drive/MyDrive/DED Codes/New images/Sample 8'\n",
        "        data = pd.read_csv('/content/drive/MyDrive/DED Codes/Porosity prediction in DED/DataPoints On Object/DataPoints Sample 8.csv')\n",
        "        angle = 105\n",
        "\n",
        "    images = []\n",
        "    for filename in os.listdir(path_img):\n",
        "        # print(filename)\n",
        "        img = cv2.imread(os.path.join(path_img, filename), cv2.IMREAD_GRAYSCALE)\n",
        "        rot = imutils.rotate_bound(img, angle=angle)\n",
        "        images.append(rot)\n",
        "\n",
        "    keys, df = get_neighborhood(data, features, depth_layer,state, num_neighbor)\n",
        "\n",
        "    return keys, df\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "LK9mBijfoGlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_each_class(cls, features , depth_layer, state, num_neighbor):\n",
        "    if cls == 'Class 1':\n",
        "       sample4 = pd.read_csv('/content/drive/MyDrive/DED Codes/Porosity prediction in DED/DataPoints On Object/DataPoints Sample 4.csv')\n",
        "       sample5 = pd.read_csv('/content/drive/MyDrive/DED Codes/Porosity prediction in DED/DataPoints On Object/DataPoints Sample 5.csv')\n",
        "       data = pd.concat([sample4, sample5])\n",
        "\n",
        "    elif cls == 'Class 2':\n",
        "       sample6 = pd.read_csv('/content/drive/MyDrive/DED Codes/Porosity prediction in DED/DataPoints On Object/DataPoints Sample 6.csv')\n",
        "       sample8 = pd.read_csv('/content/drive/MyDrive/DED Codes/Porosity prediction in DED/DataPoints On Object/DataPoints Sample 8.csv')\n",
        "       data = pd.concat([sample6, sample8])\n",
        "\n",
        "    keys, df = get_neighborhood(data, features, depth_layer,state, num_neighbor)\n",
        "\n",
        "    return keys, df\n"
      ],
      "metadata": {
        "id": "QnK1zr34Dew0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_all_samples(features , depth_layer, state, num_neighbor):\n",
        "    sample4 = pd.read_csv('/content/drive/MyDrive/DED Codes/Porosity prediction in DED/DataPoints On Object/DataPoints Sample 4.csv')\n",
        "    sample5 = pd.read_csv('/content/drive/MyDrive/DED Codes/Porosity prediction in DED/DataPoints On Object/DataPoints Sample 5.csv')\n",
        "    sample6 = pd.read_csv('/content/drive/MyDrive/DED Codes/Porosity prediction in DED/DataPoints On Object/DataPoints Sample 6.csv')\n",
        "    sample8 = pd.read_csv('/content/drive/MyDrive/DED Codes/Porosity prediction in DED/DataPoints On Object/DataPoints Sample 8.csv')\n",
        "    data = pd.concat([sample4, sample5, sample6, sample8])\n",
        "\n",
        "    keys, df = get_neighborhood(data, features, depth_layer,state, num_neighbor)\n",
        "    return keys, df"
      ],
      "metadata": {
        "id": "iibzrFYsIkqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get selected features**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zcGfYZIOIfYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10\n",
        "selected_features = ['pos_x', 'pos_y', 'pos_z', 'dist', 'sat', 'LongPeak', 'ShortPeak', 'Time', 'XPeak', 'TGrad','Label']\n",
        "\n",
        "# 6\n",
        "# selected_features = ['pos_x', 'pos_y', 'pos_z', 'ShortPeak', 'Time', 'XPeak','Label']\n",
        "# 8\n",
        "# selected_features = ['pos_x', 'pos_y', 'pos_z', 'dist', 'LongPeak', 'Time', 'XPeak','TGrad','Label']\n",
        "# 12\n",
        "# selected_features = ['pos_x', 'pos_y', 'pos_z', 'dist', 'LongPeak', 'ShortPeak', 'Time','TGrad', 'RGrad', 'velo', 'L', 'W','Label']    \n",
        "# 15   \n",
        "# selected_features = ['pos_x', 'pos_y', 'pos_z', 'dist', 'peak_temp', 'sat', 'Time', 'YPeak','TGrad', 'BGrad', 'LGrad', 'RGrad', 'velo', 'L', 'W','Label']\n",
        "\n",
        "# Sera features\n",
        "# selected_features = ['pos_x', 'pos_y', 'pos_z', 'peak_temp', 'avg_temp', 'LongPeak', 'ShortPeak', 'Time', 'velo','Label']  \n",
        "# ALL features\n",
        "# data = pd.read_csv('/content/drive/MyDrive/DED Codes/Porosity prediction in DED/DataPoints On Object/DataPoints Sample 4.csv')\n",
        "# selected_features = list(data.head())\n",
        "\n",
        "# selected_features = ['pos_x', 'pos_y', 'pos_z', 'peak_temp', 'avg_temp', 'velo','Label'] \n",
        "\n",
        "# count_f = 'Sera'\n",
        "# print(count_f)"
      ],
      "metadata": {
        "id": "eecfn6NXt6Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_f = len(selected_features)-1\n",
        "print(count_f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB_GLTNjITGh",
        "outputId": "5c43d476-201d-4fbc-bcd7-2764d8bc8fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 1: 2 layer before, 1 nearest neighbor**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "AgSOgtB-0-TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "depth_layer = 2\n",
        "num_neighbor = 1\n",
        "state = '3D'\n",
        "scen = 'Scenario 1'\n",
        "\n",
        "# Each Sample\n",
        "flag = ['Sample 4','Sample 5','Sample 6','Sample 8']\n",
        "for f in flag:\n",
        "    print(f)\n",
        "    dic_keys, dictionary = preprocess_each_sample(f, selected_features, depth_layer, state, num_neighbor)\n",
        "    for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "    df = pd.DataFrame.from_dict(dictionary) \n",
        "    df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {f}.csv', index = False, header=True)\n",
        "\n",
        "# Each Class\n",
        "cls = ['Class 1','Class 2']\n",
        "for c in cls:\n",
        "  dic_keys, dictionary = preprocess_each_class(c, selected_features, depth_layer, state, num_neighbor)\n",
        "  for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "  df = pd.DataFrame.from_dict(dictionary) \n",
        "  df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {c}.csv', index = False, header=True)\n",
        "\n",
        "# All Samples\n",
        "dic_keys, dictionary = preprocess_all_samples(selected_features, depth_layer, state, num_neighbor)\n",
        "for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "df = pd.DataFrame.from_dict(dictionary) \n",
        "df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme ALL samples.csv', index = False, header=True)"
      ],
      "metadata": {
        "id": "S-bE-svZ06t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 2: 3 layer before, 1 nearest neighbor**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-8t6n6SbwP6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depth_layer = 3\n",
        "num_neighbor = 1\n",
        "state = '3D'\n",
        "scen = 'Scenario 2'\n",
        "\n",
        "# Each Sample\n",
        "flag = ['Sample 4','Sample 5','Sample 6','Sample 8']\n",
        "for f in flag:\n",
        "    print(f)\n",
        "    dic_keys, dictionary = preprocess_each_sample(f, selected_features, depth_layer, state, num_neighbor)\n",
        "    for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "    df = pd.DataFrame.from_dict(dictionary) \n",
        "    df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {f}.csv', index = False, header=True)\n",
        "\n",
        "# Each Class\n",
        "cls = ['Class 1','Class 2']\n",
        "for c in cls:\n",
        "  dic_keys, dictionary = preprocess_each_class(c, selected_features, depth_layer, state, num_neighbor)\n",
        "  for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "  df = pd.DataFrame.from_dict(dictionary) \n",
        "  df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {c}.csv', index = False, header=True)\n",
        "\n",
        "# All Samples\n",
        "dic_keys, dictionary = preprocess_all_samples(selected_features, depth_layer, state, num_neighbor)\n",
        "for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "df = pd.DataFrame.from_dict(dictionary) \n",
        "df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme ALL Samples.csv', index = False, header=True)"
      ],
      "metadata": {
        "id": "rWi8OH6Awhd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 3: 4 layer before, 1 nearest neighbor**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3Jv4-pOIxcNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depth_layer = 4\n",
        "num_neighbor = 1\n",
        "state = '3D'\n",
        "scen = 'Scenario 3'\n",
        "\n",
        "# Each Sample\n",
        "flag = ['Sample 4','Sample 5','Sample 6','Sample 8']\n",
        "for f in flag:\n",
        "    print(f)\n",
        "    dic_keys, dictionary = preprocess_each_sample(f, selected_features, depth_layer, state, num_neighbor)\n",
        "    for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "    df = pd.DataFrame.from_dict(dictionary) \n",
        "    df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {f}.csv', index = False, header=True)\n",
        "\n",
        "# Each Class\n",
        "cls = ['Class 1','Class 2']\n",
        "for c in cls:\n",
        "  dic_keys, dictionary = preprocess_each_class(c, selected_features, depth_layer, state, num_neighbor)\n",
        "  for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "  df = pd.DataFrame.from_dict(dictionary) \n",
        "  df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {c}.csv', index = False, header=True)\n",
        "\n",
        "# All Samples\n",
        "dic_keys, dictionary = preprocess_all_samples(selected_features, depth_layer, state, num_neighbor)\n",
        "for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "df = pd.DataFrame.from_dict(dictionary) \n",
        "df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme ALL Samples.csv', index = False, header=True)"
      ],
      "metadata": {
        "id": "MApYVQKSx21D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 4: 5 layer before, 1 nearest neighbor**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HRc69Zecymq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depth_layer = 5\n",
        "num_neighbor = 1\n",
        "state = '3D'\n",
        "scen = 'Scenario 4'\n",
        "\n",
        "# Each Sample\n",
        "flag = ['Sample 4','Sample 5','Sample 6','Sample 8']\n",
        "for f in flag:\n",
        "    print(f)\n",
        "    dic_keys, dictionary = preprocess_each_sample(f, selected_features, depth_layer, state, num_neighbor)\n",
        "    for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "    df = pd.DataFrame.from_dict(dictionary) \n",
        "    df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {f}.csv', index = False, header=True)\n",
        "\n",
        "# Each Class\n",
        "cls = ['Class 1','Class 2']\n",
        "for c in cls:\n",
        "  dic_keys, dictionary = preprocess_each_class(c, selected_features, depth_layer, state, num_neighbor)\n",
        "  for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "  df = pd.DataFrame.from_dict(dictionary) \n",
        "  df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {c}.csv', index = False, header=True)\n",
        "\n",
        "# All Samples\n",
        "dic_keys, dictionary = preprocess_all_samples(selected_features, depth_layer, state, num_neighbor)\n",
        "for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "df = pd.DataFrame.from_dict(dictionary) \n",
        "df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme ALL Samples.csv', index = False, header=True)"
      ],
      "metadata": {
        "id": "KS4z7CIIytHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 5: 2 layer before, 2 nearest neighbor**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "JcUFFv8b1Cyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depth_layer = 2\n",
        "num_neighbor = 2\n",
        "state = '3D'\n",
        "scen = 'Scenario 5'\n",
        "\n",
        "# Each Sample\n",
        "flag = ['Sample 4','Sample 5','Sample 6','Sample 8']\n",
        "for f in flag:\n",
        "    print(f)\n",
        "    dic_keys, dictionary = preprocess_each_sample(f, selected_features, depth_layer, state, num_neighbor)\n",
        "    for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "    df = pd.DataFrame.from_dict(dictionary) \n",
        "    df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {f}.csv', index = False, header=True)\n",
        "\n",
        "\n",
        "# Each Class\n",
        "cls = ['Class 1','Class 2']\n",
        "for c in cls:\n",
        "  dic_keys, dictionary = preprocess_each_class(c, selected_features, depth_layer, state, num_neighbor)\n",
        "  for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "  df = pd.DataFrame.from_dict(dictionary) \n",
        "  df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {c}.csv', index = False, header=True)\n",
        "\n",
        "# All Samples\n",
        "dic_keys, dictionary = preprocess_all_samples(selected_features, depth_layer, state, num_neighbor)\n",
        "for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "df = pd.DataFrame.from_dict(dictionary) \n",
        "df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme ALL Samples.csv', index = False, header=True)"
      ],
      "metadata": {
        "id": "OnJTzEcv1Or7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 6: 2 layer before, 3 nearest neighbor**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mSQTCElx2dc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depth_layer = 2\n",
        "num_neighbor = 3\n",
        "state = '3D'\n",
        "scen = 'Scenario 6'\n",
        "\n",
        "# Each Sample\n",
        "flag = ['Sample 4','Sample 5','Sample 6','Sample 8']\n",
        "for f in flag:\n",
        "    print(f)\n",
        "    dic_keys, dictionary = preprocess_each_sample(f, selected_features, depth_layer, state, num_neighbor)\n",
        "    for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "    df = pd.DataFrame.from_dict(dictionary) \n",
        "    df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {f}.csv', index = False, header=True)\n",
        "\n",
        "# Each Class\n",
        "cls = ['Class 1','Class 2']\n",
        "for c in cls:\n",
        "  dic_keys, dictionary = preprocess_each_class(c, selected_features, depth_layer, state, num_neighbor)\n",
        "  for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "  df = pd.DataFrame.from_dict(dictionary) \n",
        "  df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {c}.csv', index = False, header=True)\n",
        "\n",
        "# All Samples\n",
        "dic_keys, dictionary = preprocess_all_samples(selected_features, depth_layer, state, num_neighbor)\n",
        "for k in flatten(dic_keys):\n",
        "    dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "df = pd.DataFrame.from_dict(dictionary) \n",
        "df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme ALL Samples.csv', index = False, header=True)"
      ],
      "metadata": {
        "id": "nCGTyhLI2zRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 7: 0 layer before, 2 nearest neighbor**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WPweNk5KFSQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depth_layer = 0\n",
        "num_neighbor = 2\n",
        "state = '2D'\n",
        "scen = 'Scenario 7'\n",
        "\n",
        "# Each Sample\n",
        "flag = ['Sample 4','Sample 5','Sample 6','Sample 8']\n",
        "for f in flag:\n",
        "    print(f)\n",
        "    dic_keys, dictionary = preprocess_each_sample(f, selected_features, depth_layer, state, num_neighbor)\n",
        "    for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "    df = pd.DataFrame.from_dict(dictionary) \n",
        "    df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {f}.csv', index = False, header=True)\n",
        "\n",
        "# Each Class\n",
        "cls = ['Class 1','Class 2']\n",
        "for c in cls:\n",
        "  dic_keys, dictionary = preprocess_each_class(c, selected_features, depth_layer, state, num_neighbor)\n",
        "  for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "  df = pd.DataFrame.from_dict(dictionary) \n",
        "  df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {c}.csv', index = False, header=True)\n",
        "\n",
        "# All Samples\n",
        "dic_keys, dictionary = preprocess_all_samples(selected_features, depth_layer, state, num_neighbor)\n",
        "for k in flatten(dic_keys):\n",
        "    dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "df = pd.DataFrame.from_dict(dictionary) \n",
        "df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme ALL Samples.csv', index = False, header=True)"
      ],
      "metadata": {
        "id": "pVwRtFuUFXly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 8: 0 layer before, 3 nearest neighbor**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WhAg39vVL_Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depth_layer = 0\n",
        "num_neighbor = 3\n",
        "state = '2D'\n",
        "scen = 'Scenario 8'\n",
        "\n",
        "# Each Sample\n",
        "flag = ['Sample 4','Sample 5','Sample 6','Sample 8']\n",
        "for f in flag:\n",
        "    print(f)\n",
        "    dic_keys, dictionary = preprocess_each_sample(f, selected_features, depth_layer, state, num_neighbor)\n",
        "\n",
        "    for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "    df = pd.DataFrame.from_dict(dictionary) \n",
        "    df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {f}.csv', index = False, header=True)\n",
        "    break\n",
        "\n",
        "# Each Class\n",
        "cls = ['Class 1','Class 2']\n",
        "for c in cls:\n",
        "  dic_keys, dictionary = preprocess_each_class(c, selected_features, depth_layer, state, num_neighbor)\n",
        "  for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "  df = pd.DataFrame.from_dict(dictionary) \n",
        "  df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {c}.csv', index = False, header=True)\n",
        "\n",
        "\n",
        "# All Samples\n",
        "dic_keys, dictionary = preprocess_all_samples(selected_features, depth_layer, state, num_neighbor)\n",
        "for k in flatten(dic_keys):\n",
        "      dictionary[k] = list(flatten(dictionary[k]))     \n",
        "    \n",
        "df = pd.DataFrame.from_dict(dictionary) \n",
        "df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme ALL Samples.csv', index = False, header=True)"
      ],
      "metadata": {
        "id": "WVDFMlh5MFrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combine scenarios: 9, 10**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bcWrJzX5ZJT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine(f,nb,smp):\n",
        "    dic_keys = []\n",
        "    dic_list = []\n",
        "    for s in state:\n",
        "      if s == '3D':\n",
        "        depth_layer = 2\n",
        "        num_neighbor = nb\n",
        "      elif s == '2D':\n",
        "        depth_layer = 2\n",
        "        num_neighbor = 2  \n",
        "      # --------------------------------------\n",
        "      if smp == 'Each sample':\n",
        "        key, dictionary = preprocess_each_sample(f, selected_features, depth_layer, s, num_neighbor)\n",
        "      if smp == 'class':\n",
        "        key, dictionary = preprocess_each_class(f, selected_features, depth_layer, s, num_neighbor)\n",
        "      if smp == 'All':\n",
        "        key, dictionary = preprocess_all_samples(selected_features, depth_layer, s, num_neighbor)\n",
        "      # ---------------------------------------\n",
        "      dic_keys.append(key)\n",
        "      dic_list.append(dictionary)\n",
        "\n",
        "    dic1 = dic_list[0]\n",
        "    dic2 = dic_list[1]\n",
        "\n",
        "    for fea in selected_features:\n",
        "      del dic2[fea] \n",
        "    dic1.update(dic2)\n",
        "\n",
        "    for k in flatten(dic_keys):\n",
        "      dic1[k] = list(flatten(dic1[k]))     \n",
        "    \n",
        "    df = pd.DataFrame.from_dict(dic1) \n",
        "    label_col = df.pop('Label')\n",
        "    df.insert(len(df.columns), 'Label', label_col)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "uHKWIYyhZQ7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 9: 2 layer before in each 1 NN, Current layer 2 nearest neighbor**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dF2tbmt_9kQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "state = ['3D','2D']\n",
        "scen = 'Scenario 9'\n",
        "nb = 1\n",
        "# Each Sample\n",
        "flag = ['Sample 4','Sample 5','Sample 6','Sample 8']\n",
        "smp = 'Each sample'\n",
        "for f in flag:\n",
        "    print(f)\n",
        "    df = combine(f,nb,smp)\n",
        "    df.to_csv(f'/content/drive/MyDrive/DED Codes/Porosity prediction in DED/Neighborhood Schemes - Mutual Information Reg - 10 F/{scen}/Scheme {f}.csv', index = False, header=True)\n",
        "    break\n",
        "\n",
        "\n",
        "# # Each Class\n",
        "# cls = ['Class 1','Class 2']\n",
        "# for c in cls:\n",
        "#   smp = 'class'\n",
        "#   df = combine(c,nb,smp)\n",
        "#   df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {c}.csv', index = False, header=True)\n",
        "\n",
        "# # All Samples\n",
        "# smp = 'All'\n",
        "# df = combine(f,nb,smp)\n",
        "# df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme ALL Samples.csv', index = False, header=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IQ2Y9zr9pa8",
        "outputId": "a88063d2-061b-486b-8fff-b7f1f6d89f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 4\n",
            "dic keys: ['pos_x', 'pos_y', 'pos_z', 'dist', 'sat', 'LongPeak', 'ShortPeak', 'Time', 'XPeak', 'TGrad', 'pos_x-1|N1', 'pos_y-1|N1', 'pos_z-1|N1', 'dist-1|N1', 'sat-1|N1', 'LongPeak-1|N1', 'ShortPeak-1|N1', 'Time-1|N1', 'XPeak-1|N1', 'TGrad-1|N1', 'Label-1|N1', 'pos_x-2|N1', 'pos_y-2|N1', 'pos_z-2|N1', 'dist-2|N1', 'sat-2|N1', 'LongPeak-2|N1', 'ShortPeak-2|N1', 'Time-2|N1', 'XPeak-2|N1', 'TGrad-2|N1', 'Label-2|N1', 'Label']\n",
            "dic keys: ['pos_x', 'pos_y', 'pos_z', 'dist', 'sat', 'LongPeak', 'ShortPeak', 'Time', 'XPeak', 'TGrad', 'pos_x|N1', 'pos_y|N1', 'pos_z|N1', 'dist|N1', 'sat|N1', 'LongPeak|N1', 'ShortPeak|N1', 'Time|N1', 'XPeak|N1', 'TGrad|N1', 'Label|N1', 'pos_x|N2', 'pos_y|N2', 'pos_z|N2', 'dist|N2', 'sat|N2', 'LongPeak|N2', 'ShortPeak|N2', 'Time|N2', 'XPeak|N2', 'TGrad|N2', 'Label|N2', 'Label']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 10: 2 layer before in each 2 NN, Current layer 2 nearest neighbor**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "XIHRF7XyVeNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "state = ['3D','2D']\n",
        "scen = 'Scenario 10'\n",
        "nb = 2\n",
        "# Each Sample\n",
        "flag = ['Sample 4','Sample 5','Sample 6','Sample 8']\n",
        "smp = 'Each sample'\n",
        "for f in flag:\n",
        "    print(f)\n",
        "    df = combine(f,nb,smp)\n",
        "    df.to_csv(f'/content/drive/MyDrive/DED Codes/Porosity prediction in DED/Neighborhood Schemes - Mutual Information Reg - 10 F/{scen}/Scheme {f}.csv', index = False, header=True)\n",
        "    break\n",
        "\n",
        "\n",
        "# Each Class\n",
        "# cls = ['Class 1','Class 2']\n",
        "# for c in cls:\n",
        "#   smp = 'class'\n",
        "#   df = combine(c,nb,smp)\n",
        "#   df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme {c}.csv', index = False, header=True)\n",
        "\n",
        "# # All Samples\n",
        "# smp = 'All'\n",
        "# df = combine(f,nb,smp)\n",
        "# df.to_csv(f'/content/drive/MyDrive/DED Codes/Dataset Pointwise/{scen}/Scheme ALL Samples.csv', index = False, header=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKNqjTa_VktR",
        "outputId": "5a498666-a51d-4104-b8c3-6b572392dc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 4\n",
            "dic keys: ['pos_x', 'pos_y', 'pos_z', 'dist', 'sat', 'LongPeak', 'ShortPeak', 'Time', 'XPeak', 'TGrad', 'pos_x-1|N1', 'pos_y-1|N1', 'pos_z-1|N1', 'dist-1|N1', 'sat-1|N1', 'LongPeak-1|N1', 'ShortPeak-1|N1', 'Time-1|N1', 'XPeak-1|N1', 'TGrad-1|N1', 'Label-1|N1', 'pos_x-1|N2', 'pos_y-1|N2', 'pos_z-1|N2', 'dist-1|N2', 'sat-1|N2', 'LongPeak-1|N2', 'ShortPeak-1|N2', 'Time-1|N2', 'XPeak-1|N2', 'TGrad-1|N2', 'Label-1|N2', 'pos_x-2|N1', 'pos_y-2|N1', 'pos_z-2|N1', 'dist-2|N1', 'sat-2|N1', 'LongPeak-2|N1', 'ShortPeak-2|N1', 'Time-2|N1', 'XPeak-2|N1', 'TGrad-2|N1', 'Label-2|N1', 'pos_x-2|N2', 'pos_y-2|N2', 'pos_z-2|N2', 'dist-2|N2', 'sat-2|N2', 'LongPeak-2|N2', 'ShortPeak-2|N2', 'Time-2|N2', 'XPeak-2|N2', 'TGrad-2|N2', 'Label-2|N2', 'Label']\n",
            "dic keys: ['pos_x', 'pos_y', 'pos_z', 'dist', 'sat', 'LongPeak', 'ShortPeak', 'Time', 'XPeak', 'TGrad', 'pos_x|N1', 'pos_y|N1', 'pos_z|N1', 'dist|N1', 'sat|N1', 'LongPeak|N1', 'ShortPeak|N1', 'Time|N1', 'XPeak|N1', 'TGrad|N1', 'Label|N1', 'pos_x|N2', 'pos_y|N2', 'pos_z|N2', 'dist|N2', 'sat|N2', 'LongPeak|N2', 'ShortPeak|N2', 'Time|N2', 'XPeak|N2', 'TGrad|N2', 'Label|N2', 'Label']\n"
          ]
        }
      ]
    }
  ]
}